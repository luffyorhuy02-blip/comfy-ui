{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé§ Clone Voice v·ªõi RVC (Retrieval-based Voice Conversion)\n",
                "Notebook ƒë·ªÉ train v√† s·ª≠ d·ª•ng RVC clone gi·ªçng n√≥i tr√™n Google Colab\n",
                "\n",
                "**Y√™u c·∫ßu:** GPU T4/A100 (ch·ªçn Runtime > Change runtime type > GPU)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 1Ô∏è‚É£ KEEP ALIVE (Ch·∫°y ng·∫ßm tr√°nh disconnect)\n",
                "import time, random, threading, gc\n",
                "from IPython.display import display, Javascript\n",
                "\n",
                "# JavaScript Keep Alive\n",
                "display(Javascript('''\n",
                "(function(){\n",
                "    let count = 0;\n",
                "    function keepAlive() {\n",
                "        count++;\n",
                "        console.log(\"Keep alive tick: \" + count);\n",
                "        document.querySelector(\"colab-connect-button\")?.click();\n",
                "        \n",
                "        // Sim UI update\n",
                "        var status = document.getElementById(\"ka-status\");\n",
                "        if (status) status.innerHTML = \"üîÑ Active: \" + count;\n",
                "\n",
                "        setTimeout(keepAlive, 25000 + Math.random() * 15000);\n",
                "    }\n",
                "    \n",
                "    // Create Status UI\n",
                "    var div = document.createElement(\"div\");\n",
                "    div.id = \"ka-status\";\n",
                "    div.innerHTML = \"üîÑ ON\";\n",
                "    div.style.cssText = \"position: fixed; top: 10px; right: 10px; background: linear-gradient(135deg, #FF6B6B, #556270); color: white; padding: 8px 15px; border-radius: 20px; z-index: 9999; font-family: sans-serif; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\";\n",
                "    document.body.appendChild(div);\n",
                "    \n",
                "    keepAlive();\n",
                "})();\n",
                "'''))\n",
                "\n",
                "# Python Keep Alive Background Thread\n",
                "def py_keep_alive():\n",
                "    while True:\n",
                "        time.sleep(random.randint(30, 90))\n",
                "        gc.collect() # Memory cleanup to fake activity\n",
                "        \n",
                "threading.Thread(target=py_keep_alive, daemon=True).start()\n",
                "print(\"‚úÖ Keep Alive activated!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 2Ô∏è‚É£ Ki·ªÉm tra GPU\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 3Ô∏è‚É£ Clone RVC v√† c√†i ƒë·∫∑t dependencies\n",
                "%cd /content\n",
                "\n",
                "# Clone RVC WebUI\n",
                "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
                "%cd Retrieval-based-Voice-Conversion-WebUI\n",
                "\n",
                "# C√†i dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
                "!pip install -q faiss-gpu\n",
                "!pip install -q gradio==3.50.2\n",
                "!pip install -q edge-tts  # Th∆∞ vi·ªán TTS ƒë·ªÉ t·∫°o gi·ªçng ƒë·ªçc m·∫´u\n",
                "\n",
                "print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 4Ô∏è‚É£ Download pretrained models\n",
                "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
                "\n",
                "# Download Hubert model\n",
                "!mkdir -p assets/hubert\n",
                "!wget -q -O assets/hubert/hubert_base.pt https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt\n",
                "\n",
                "# Download RMVPE model (pitch extraction)\n",
                "!mkdir -p assets/rmvpe\n",
                "!wget -q -O assets/rmvpe/rmvpe.pt https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt\n",
                "\n",
                "# Download pretrained models\n",
                "!mkdir -p assets/pretrained_v2\n",
                "!wget -q -O assets/pretrained_v2/f0G48k.pth https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G48k.pth\n",
                "!wget -q -O assets/pretrained_v2/f0D48k.pth https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D48k.pth\n",
                "\n",
                "print(\"‚úÖ ƒê√£ download xong pretrained models!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 5Ô∏è‚É£ Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ\n",
                "!mkdir -p /content/drive/MyDrive/rvc_training/audio\n",
                "!mkdir -p /content/drive/MyDrive/rvc_training/models\n",
                "print(\"‚úÖ ƒê√£ mount Drive v√† t·∫°o th∆∞ m·ª•c!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 6Ô∏è‚É£ C·∫•u h√¨nh Training\n",
                "\n",
                "# === C·∫§U H√åNH CH√çNH ===\n",
                "MODEL_NAME = \"my_voice\"  #@param {type:\"string\"}\n",
                "\n",
                "# Th∆∞ m·ª•c ch·ª©a file audio training (upload v√†o Drive)\n",
                "AUDIO_DIR = \"/content/drive/MyDrive/rvc_training/audio\"  #@param {type:\"string\"}\n",
                "OUTPUT_DIR = \"/content/drive/MyDrive/rvc_training/models\"  #@param {type:\"string\"}\n",
                "\n",
                "# Training parameters\n",
                "SAMPLE_RATE = 48000  #@param [40000, 48000]\n",
                "BATCH_SIZE = 8  #@param {type:\"integer\"}\n",
                "TOTAL_EPOCHS = 100  #@param {type:\"integer\"}\n",
                "SAVE_EVERY_EPOCH = 10  #@param {type:\"integer\"}\n",
                "\n",
                "# F0 method\n",
                "F0_METHOD = \"rmvpe\"  #@param [\"rmvpe\", \"crepe\", \"harvest\"]\n",
                "\n",
                "print(f\"‚úÖ C·∫•u h√¨nh xong! Model: {MODEL_NAME}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 7Ô∏è‚É£ Ti·ªÅn x·ª≠ l√Ω Audio (Train Only)\n",
                "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "# Copy audio files v√†o th∆∞ m·ª•c training\n",
                "train_dir = f\"logs/{MODEL_NAME}\"\n",
                "os.makedirs(train_dir, exist_ok=True)\n",
                "\n",
                "# Ki·ªÉm tra audio files\n",
                "if os.path.exists(AUDIO_DIR):\n",
                "    audio_files = [f for f in os.listdir(AUDIO_DIR) if f.endswith(('.wav', '.mp3', '.flac', '.ogg'))]\n",
                "    print(f\"T√¨m th·∫•y {len(audio_files)} file audio:\")\n",
                "    for f in audio_files:\n",
                "        print(f\"  - {f}\")\n",
                "    \n",
                "    if len(audio_files) > 0:\n",
                "        !python infer/modules/train/preprocess.py \"{AUDIO_DIR}\" {SAMPLE_RATE} 2 \"logs/{MODEL_NAME}\" False 3.0\n",
                "        print(\"\\n‚úÖ ƒê√£ ti·ªÅn x·ª≠ l√Ω audio xong!\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file audio ƒë·ªÉ train. (N·∫øu ch·ªâ d√πng Inference th√¨ b·ªè qua)\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Th∆∞ m·ª•c audio ch∆∞a t·ªìn t·∫°i. (N·∫øu ch·ªâ d√πng Inference th√¨ b·ªè qua)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 8Ô∏è‚É£ Extract Features & Train (Train Only)\n",
                "# SKIP n·∫øu b·∫°n ch·ªâ ch·∫°y Inference\n",
                "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
                "\n",
                "# Extract features\n",
                "import os\n",
                "if os.path.exists(f\"logs/{MODEL_NAME}\") and os.listdir(f\"logs/{MODEL_NAME}\"):\n",
                "    !python infer/modules/train/extract/extract_feature_print.py cuda:0 1 0 0 \"logs/{MODEL_NAME}\" \"v2\"\n",
                "    !python infer/modules/train/extract_f0_print.py \"logs/{MODEL_NAME}\" 2 \"{F0_METHOD}\"\n",
                "\n",
                "    # Train\n",
                "    !python infer/modules/train/train.py -e \"{MODEL_NAME}\" -sr {SAMPLE_RATE} -f0 1 -bs {BATCH_SIZE} -te {TOTAL_EPOCHS} -se {SAVE_EVERY_EPOCH} -pg \"assets/pretrained_v2/f0G48k.pth\" -pd \"assets/pretrained_v2/f0D48k.pth\" -l 0 -c 0 -sw 0 -v \"v2\"\n",
                "\n",
                "    # Create Index\n",
                "    !python infer/modules/train/extract_index.py \"logs/{MODEL_NAME}\" \"v2\"\n",
                "    \n",
                "    print(\"‚úÖ Training ho√†n t·∫•t!\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ train.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 9Ô∏è‚É£ Setup API Interface (TTS + RVC)\n",
                "# C√†i Cloudflared\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
                "!dpkg -i cloudflared-linux-amd64.deb\n",
                "\n",
                "import sys, os, glob, asyncio, edge_tts, subprocess, threading, time\n",
                "import gradio as gr\n",
                "import soundfile as sf\n",
                "from google.colab import userdata\n",
                "\n",
                "sys.path.append('/content/Retrieval-based-Voice-Conversion-WebUI')\n",
                "from infer.modules.vc.modules import VC\n",
                "from configs.config import Config\n",
                "\n",
                "# Init RVC\n",
                "config = Config()\n",
                "vc = VC(config)\n",
                "\n",
                "# Load Model t·ª± ƒë·ªông (L·∫•y model v·ª´a train ho·∫∑c upload)\n",
                "try:\n",
                "    # ∆Øu ti√™n l·∫•y t·ª´ Logs (model v·ª´a train)\n",
                "    model_path = glob.glob(f\"logs/{MODEL_NAME}/*G_*.pth\")[-1]\n",
                "    # Ho·∫∑c l·∫•y t·ª´ Weights\n",
                "    # model_path = glob.glob(f\"assets/weights/{MODEL_NAME}*.pth\")[0]\n",
                "    \n",
                "    index_path = glob.glob(f\"logs/{MODEL_NAME}/*.index\")[-1]\n",
                "    vc.get_vc(model_path)\n",
                "    print(f\"‚úÖ ƒê√£ load model: {model_path}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Ch∆∞a load ƒë∆∞·ª£c model: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i path.\")\n",
                "\n",
                "# --- H√ÄM X·ª¨ L√ù CH√çNH ---\n",
                "async def text_to_speech_edge(text, voice):\n",
                "    # List voices: vi-VN-HoaiMyNeural, vi-VN-NamMinhNeural, en-US-AriaNeural...\n",
                "    communicate = edge_tts.Communicate(text, voice)\n",
                "    temp_file = \"/content/tts_temp.mp3\"\n",
                "    await communicate.save(temp_file)\n",
                "    return temp_file\n",
                "\n",
                "def process_pipeline(text, voice_name, pitch_change, index_rate):\n",
                "    if not text:\n",
                "        return None, \"Vui l√≤ng nh·∫≠p text!\"\n",
                "    \n",
                "    # 1. TTS\n",
                "    tts_start = time.time()\n",
                "    try:\n",
                "        audio_path = asyncio.run(text_to_speech_edge(text, voice_name))\n",
                "    except Exception as e:\n",
                "        return None, f\"L·ªói TTS: {str(e)}\"\n",
                "    \n",
                "    # 2. RVC Conversion\n",
                "    try:\n",
                "        wav_opt = vc.vc_single(\n",
                "            sid=0,\n",
                "            input_audio_path=audio_path,\n",
                "            f0_up_key=pitch_change,\n",
                "            f0_method=\"rmvpe\",\n",
                "            index_file=index_path,\n",
                "            index_rate=index_rate,\n",
                "            filter_radius=3,\n",
                "            resample_sr=0,\n",
                "            rms_mix_rate=0.25,\n",
                "            protect=0.33\n",
                "        )\n",
                "        if wav_opt[0] == \"Success\":\n",
                "            return (wav_opt[1][0], wav_opt[1][1]), \"‚úÖ Th√†nh c√¥ng!\"\n",
                "        else:\n",
                "            return None, f\"L·ªói RVC: {wav_opt[0]}\"\n",
                "    except Exception as e:\n",
                "        return None, f\"L·ªói Process: {str(e)}\"\n",
                "\n",
                "# --- GRADIO INTERFACE ---\n",
                "with gr.Blocks(title=\"RVC Voice Clone API\") as app:\n",
                "    gr.Markdown(\"# üéôÔ∏è Voice Clone API (TTS + RVC)\")\n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            txt_input = gr.Textbox(label=\"Nh·∫≠p vƒÉn b·∫£n\", lines=3, placeholder=\"Xin ch√†o, t√¥i l√† AI...\")\n",
                "            voice_sel = gr.Dropdown(label=\"Gi·ªçng ƒë·ªçc m·∫´u (TTS)\", choices=[\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"en-US-AriaNeural\"], value=\"vi-VN-HoaiMyNeural\")\n",
                "            pitch = gr.Slider(label=\"ƒê·ªïi t√¥ng (Pitch)\", minimum=-12, maximum=12, value=0, step=1)\n",
                "            index_rate = gr.Slider(label=\"Index Rate (ƒê·ªô gi·ªëng)\", minimum=0, maximum=1, value=0.75)\n",
                "            btn = gr.Button(\"üöÄ T·∫°o gi·ªçng n√≥i\", variant=\"primary\")\n",
                "        with gr.Column():\n",
                "            audio_out = gr.Audio(label=\"K·∫øt qu·∫£\")\n",
                "            status = gr.Textbox(label=\"Tr·∫°ng th√°i\")\n",
                "\n",
                "    btn.click(process_pipeline, inputs=[txt_input, voice_sel, pitch, index_rate], outputs=[audio_out, status])\n",
                "\n",
                "# --- CLOUDFLARE TUNNEL ---\n",
                "try:\n",
                "    TOKEN = userdata.get('CLOUDFLARE_TOKEN')\n",
                "except:\n",
                "    TOKEN = \"\"\n",
                "\n",
                "if not TOKEN:\n",
                "    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Secret 'CLOUDFLARE_TOKEN'. Ch·∫°y local mode.\")\n",
                "    app.queue().launch(share=True)\n",
                "else:\n",
                "    print(\"üöÄ Kh·ªüi ƒë·ªông Cloudflare Tunnel...\")\n",
                "    threading.Thread(target=lambda: subprocess.run([\"cloudflared\", \"tunnel\", \"run\", \"--token\", TOKEN]), daemon=True).start()\n",
                "    time.sleep(5)\n",
                "    print(f\"üåê API s·∫µn s√†ng t·∫°i: https://comfyui.maymoc.shop\")\n",
                "    app.queue().launch(server_name=\"0.0.0.0\", server_port=8188, quiet=True)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}